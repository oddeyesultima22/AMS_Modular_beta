{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pynnote-Whisper model for AMS"
      ],
      "metadata": {
        "id": "Q1MWinQgskJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! pip install -q git+https://github.com/pyannote/pyannote-audio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4OUcUeBk5IR",
        "outputId": "7858e474-0f4b-4406-980c-5cb8e3e4165f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-xyb_zvx7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-xyb_zvx7\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.5)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.3.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.15.4)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802824 sha256=d97ffa4ecbed6b893f8cb7c22b0965278b3a5694af953421cdc9e6095cb92055\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pk29w6mh/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.1/760.1 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyannote.audio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su-69gDlwnCZ",
        "outputId": "9217280c-03c5-41ba-8f1c-33eafdce1733"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/sampleCall1.wav'# upload the sample to google driver\n",
        "#path = os.getcwd() # to get current path\n",
        "print(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnHVVyUbw7TX",
        "outputId": "2189546c-104b-47d9-afa8-fbf28e56ddd7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/sampleCall1.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import whisper\n",
        "from pyannote.audio import Pipeline\n",
        "from pyannote.core import Segment, Annotation, Timeline\n",
        "\n",
        "# Define helper functions\n",
        "def get_text_with_timestamp(transcribe_res):\n",
        "    timestamp_texts = []\n",
        "    for item in transcribe_res['segments']:\n",
        "        start = item['start']\n",
        "        end = item['end']\n",
        "        text = item['text']\n",
        "        timestamp_texts.append((Segment(start, end), text))\n",
        "    return timestamp_texts\n",
        "\n",
        "def add_speaker_info_to_text(timestamp_texts, ann):\n",
        "    spk_text = []\n",
        "    for seg, text in timestamp_texts:\n",
        "        spk = ann.crop(seg).argmax()\n",
        "        spk_text.append((seg, spk, text))\n",
        "    return spk_text\n",
        "\n",
        "def merge_cache(text_cache):\n",
        "    sentence = ''.join([item[-1] for item in text_cache])\n",
        "    spk = text_cache[0][1]\n",
        "    start = text_cache[0][0].start\n",
        "    end = text_cache[-1][0].end\n",
        "    return Segment(start, end), spk, sentence\n",
        "\n",
        "PUNC_SENT_END = ['.', '?', '!']\n",
        "\n",
        "def merge_sentence(spk_text):\n",
        "    merged_spk_text = []\n",
        "    pre_spk = None\n",
        "    text_cache = []\n",
        "    for seg, spk, text in spk_text:\n",
        "        if spk != pre_spk and pre_spk is not None and len(text_cache) > 0:\n",
        "            merged_spk_text.append(merge_cache(text_cache))\n",
        "            text_cache = [(seg, spk, text)]\n",
        "            pre_spk = spk\n",
        "        elif text and len(text) > 0 and text[-1] in PUNC_SENT_END:\n",
        "            text_cache.append((seg, spk, text))\n",
        "            merged_spk_text.append(merge_cache(text_cache))\n",
        "            text_cache = []\n",
        "            pre_spk = spk\n",
        "        else:\n",
        "            text_cache.append((seg, spk, text))\n",
        "            pre_spk = spk\n",
        "    if len(text_cache) > 0:\n",
        "        merged_spk_text.append(merge_cache(text_cache))\n",
        "    return merged_spk_text\n",
        "\n",
        "def diarize_text(transcribe_res, diarization_result):\n",
        "    timestamp_texts = get_text_with_timestamp(transcribe_res)\n",
        "    spk_text = add_speaker_info_to_text(timestamp_texts, diarization_result)\n",
        "    res_processed = merge_sentence(spk_text)\n",
        "    return res_processed"
      ],
      "metadata": {
        "id": "k7Jfx8OI-jzB"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "from pyannote.audio import Pipeline\n",
        "from pyannote.core import Segment\n",
        "import csv\n",
        "\n",
        "# Takes 6 minutes to run a audio file\n",
        "# Define helper functions\n",
        "def get_text_with_timestamp(transcribe_res):\n",
        "    timestamp_texts = []\n",
        "    for item in transcribe_res['segments']:\n",
        "        start = item['start']\n",
        "        end = item['end']\n",
        "        text = item['text']\n",
        "        timestamp_texts.append((Segment(start, end), text))\n",
        "    return timestamp_texts\n",
        "\n",
        "def add_speaker_info_to_text(timestamp_texts, ann):\n",
        "    spk_text = []\n",
        "    for seg, text in timestamp_texts:\n",
        "        spk = ann.crop(seg).argmax()\n",
        "        spk_text.append((seg, spk, text))\n",
        "    return spk_text\n",
        "\n",
        "def merge_cache(text_cache):\n",
        "    sentence = ''.join([item[-1] for item in text_cache])\n",
        "    spk = text_cache[0][1]\n",
        "    start = text_cache[0][0].start\n",
        "    end = text_cache[-1][0].end\n",
        "    return Segment(start, end), spk, sentence\n",
        "\n",
        "PUNC_SENT_END = ['.', '?', '!']\n",
        "\n",
        "def merge_sentence(spk_text):\n",
        "    merged_spk_text = []\n",
        "    pre_spk = None\n",
        "    text_cache = []\n",
        "    for seg, spk, text in spk_text:\n",
        "        if spk != pre_spk and pre_spk is not None and len(text_cache) > 0:\n",
        "            merged_spk_text.append(merge_cache(text_cache))\n",
        "            text_cache = [(seg, spk, text)]\n",
        "            pre_spk = spk\n",
        "        elif text and len(text) > 0 and text[-1] in PUNC_SENT_END:\n",
        "            text_cache.append((seg, spk, text))\n",
        "            merged_spk_text.append(merge_cache(text_cache))\n",
        "            text_cache = []\n",
        "            pre_spk = spk\n",
        "        else:\n",
        "            text_cache.append((seg, spk, text))\n",
        "            pre_spk = spk\n",
        "    if len(text_cache) > 0:\n",
        "        merged_spk_text.append(merge_cache(text_cache))\n",
        "    return merged_spk_text\n",
        "\n",
        "def diarize_text(transcribe_res, diarization_result):\n",
        "    timestamp_texts = get_text_with_timestamp(transcribe_res)\n",
        "    spk_text = add_speaker_info_to_text(timestamp_texts, diarization_result)\n",
        "    res_processed = merge_sentence(spk_text)\n",
        "    return res_processed\n",
        "\n",
        "# Main processing workflow\n",
        "def process_audio(audio_file, auth_token):\n",
        "    # Initialize pipeline and model\n",
        "    print(\"Initializing models...\")\n",
        "    try:\n",
        "        pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\",\n",
        "                                            use_auth_token=auth_token)\n",
        "        model = whisper.load_model(\"tiny.en\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during model initialization: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Perform transcription and speaker diarization\n",
        "    print(\"Processing audio for transcription and diarization...\")\n",
        "    try:\n",
        "        asr_result = model.transcribe(audio_file)\n",
        "        diarization_result = pipeline(audio_file)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during processing: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Merge results\n",
        "    print(\"Merging transcription and diarization results...\")\n",
        "    final_result = diarize_text(asr_result, diarization_result)\n",
        "\n",
        "    if not final_result:\n",
        "        print(\"No results obtained after merging.\")\n",
        "    else:\n",
        "        print(\"Processing complete.\")\n",
        "\n",
        "    return final_result\n",
        "\n",
        "# Usage example\n",
        "audio_file = path # Update with your actual file path\n",
        "auth_token = \"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\"  # Set up your token in Hugging Face\n",
        "output_csv = \"/content/drive/MyDrive/output.csv\"  # Specify the CSV file path\n",
        "\n",
        "# Process the audio and get the results\n",
        "result = process_audio(audio_file, auth_token)\n",
        "\n",
        "# Check if the result is valid before attempting to print and save\n",
        "if result:\n",
        "    print(\"Saving the final result to CSV...\")\n",
        "    try:\n",
        "        with open(output_csv, mode='w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([\"Start Time\", \"End Time\", \"Speaker\", \"Text\"])\n",
        "            for seg, spk, sent in result:\n",
        "                line = f'{seg.start:.2f} {seg.end:.2f} {spk} {sent}'\n",
        "                print(line)\n",
        "                writer.writerow([f'{seg.start:.2f}', f'{seg.end:.2f}', spk, sent])\n",
        "        print(f\"Results successfully saved to {output_csv}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving CSV file: {e}\")\n",
        "else:\n",
        "    print(\"No result to print or save.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ISA3N9y8Km3",
        "outputId": "d3cade85-47d3-4ef2-ed49-d303268f1c4e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing models...\n",
            "Processing audio for transcription and diarization...\n",
            "Merging transcription and diarization results...\n",
            "Processing complete.\n",
            "Saving the final result to CSV...\n",
            "0.00 9.00 SPEAKER_00  Thank you for calling Nissan.\n",
            "9.00 10.00 SPEAKER_00  My name is Lauren.\n",
            "10.00 11.00 SPEAKER_00  Can I have your name?\n",
            "11.00 13.00 SPEAKER_01  My name is John Smith.\n",
            "13.00 14.00 SPEAKER_00  Thank you, John.\n",
            "14.00 15.00 SPEAKER_00  How can I help you?\n",
            "15.00 20.00 SPEAKER_01  I was just calling about to see how much it would cost to update the map in my car.\n",
            "20.00 22.00 SPEAKER_00  I'd be happy to help you with that today.\n",
            "22.00 24.00 SPEAKER_00  Did you receive a mailer from us?\n",
            "24.00 25.00 SPEAKER_01  I did.\n",
            "25.00 26.00 SPEAKER_01  Do you need the customer number?\n",
            "26.00 27.00 SPEAKER_00  Yes, please.\n",
            "27.00 28.00 SPEAKER_01  Okay.\n",
            "28.00 30.00 SPEAKER_01  It's 1-5-2-4-3.\n",
            "30.00 31.00 SPEAKER_01  Thank you.\n",
            "31.00 33.00 SPEAKER_00  And the year making model of your vehicle?\n",
            "33.00 36.00 SPEAKER_01  Yeah, I have a 2009 Nissan Altima.\n",
            "36.00 38.00 SPEAKER_01  Oh, nice car.\n",
            "38.00 39.00 SPEAKER_00  Yeah, thank you.\n",
            "39.00 40.00 SPEAKER_01  We really enjoy it.\n",
            "40.00 43.00 SPEAKER_00  Okay, I think I found your profile here.\n",
            "43.00 46.00 SPEAKER_00  Can I have you verify your address and phone number, please?\n",
            "46.00 50.00 SPEAKER_01  Yes, it's 1255 North Research Way.\n",
            "50.00 53.00 SPEAKER_01  That's an RMUTA 84097.\n",
            "53.00 58.00 SPEAKER_01  And my phone number is 801-431-1000.\n",
            "58.00 59.00 SPEAKER_00  Thanks, John.\n",
            "59.00 61.00 SPEAKER_00  I located your information.\n",
            "61.00 68.00 SPEAKER_00  The newest version we have available for your vehicle is version 7.7, which was released in March of 2012.\n",
            "68.00 72.00 SPEAKER_00  The price of the new map is $99 plus shipping and tax.\n",
            "72.00 75.00 SPEAKER_00  Let me go ahead and set up this order for you.\n",
            "75.00 77.00 SPEAKER_01  Well, can we wait just a second?\n",
            "77.00 79.00 SPEAKER_01  I'm not really sure if I can afford it right now.\n",
            "79.00 83.00 SPEAKER_00  All right, well, here are a few reasons to consider purchasing today.\n",
            "83.00 87.00 SPEAKER_00  It looks as though you have an updated your vehicle for three years.\n",
            "87.00 91.00 SPEAKER_00  So that would be the equivalent of getting three years' worth of updates for the price of one.\n",
            "91.00 92.00 SPEAKER_01  Okay.\n",
            "92.00 97.00 SPEAKER_00  In addition, special offers like the current promotion don't come around too often.\n",
            "97.00 102.00 SPEAKER_00  I would definitely recommend taking advantage of the extra $50 off before it expires.\n",
            "102.00 104.00 SPEAKER_01  Yeah, that did sound pretty good.\n",
            "104.00 108.00 SPEAKER_00  If I set this order up for you now, it'll ship out today and for $50.\n",
            "108.00 109.00 SPEAKER_00  less.\n",
            "109.00 113.00 SPEAKER_00  Do you have your credit card handy and I can place this order for you now?\n",
            "113.00 117.00 SPEAKER_01  Yeah, let's go ahead and use your visa.\n",
            "117.00 118.00 SPEAKER_01  My number is...\n",
            "Results successfully saved to /content/drive/MyDrive/output.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFF7bReSErJP",
        "outputId": "df15c033-592f-4c16-be9a-286816abbdb1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.5)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=f294e402eed5557d016d84620fb942b0d15e55223b83da2926d0aa638a41bcf5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Function to read a CSV file and return lists of text and speaker information\n",
        "def read_csv(file_path):\n",
        "    texts = []\n",
        "    speakers = []\n",
        "    with open(file_path, mode='r') as file:\n",
        "        reader = csv.reader(file)\n",
        "        next(reader)  # Skip the header row\n",
        "        for row in reader:\n",
        "            start_time = float(row[0])  # Convert start time to float\n",
        "            end_time = float(row[1])    # Convert end time to float\n",
        "            speaker = row[2]            # Keep speaker as a string\n",
        "            text = row[3]               # Extract text content\n",
        "            speakers.append(speaker)   # Append speaker information\n",
        "            texts.append(text)         # Append text content\n",
        "    return texts, speakers\n",
        "\n",
        "# Function to compare speaker segmentation between machine-generated and human-transcribed data\n",
        "def compare_speakers(machine_speakers, human_speakers):\n",
        "    if len(machine_speakers) != len(human_speakers):\n",
        "        raise ValueError(\"Length of machine speakers and human speakers lists do not match.\")\n",
        "\n",
        "    correct = 0\n",
        "    total = len(machine_speakers)\n",
        "\n",
        "    for m_spk, h_spk in zip(machine_speakers, human_speakers):\n",
        "        if m_spk == h_spk:\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "    print(f\"Speaker Segmentation Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Function to calculate ROUGE scores and display results\n",
        "def calculate_rouge(machine_texts, human_texts):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "    total_rouge1, total_rouge2, total_rougeL = 0, 0, 0\n",
        "    num_comparisons = min(len(machine_texts), len(human_texts))\n",
        "\n",
        "    for i in range(num_comparisons):\n",
        "        machine_text = machine_texts[i]\n",
        "        human_text = human_texts[i]\n",
        "\n",
        "        # Calculate ROUGE scores for the current segment\n",
        "        scores = scorer.score(human_text, machine_text)\n",
        "\n",
        "        # Print ROUGE scores for the current segment\n",
        "        print(f\"Comparison {i+1}:\")\n",
        "        print(f\"Machine Text: {machine_text}\")\n",
        "        print(f\"Human Text: {human_text}\")\n",
        "        print(f\"ROUGE-1: {scores['rouge1'].fmeasure:.4f}\")\n",
        "        print(f\"ROUGE-2: {scores['rouge2'].fmeasure:.4f}\")\n",
        "        print(f\"ROUGE-L: {scores['rougeL'].fmeasure:.4f}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Accumulate ROUGE scores\n",
        "        total_rouge1 += scores['rouge1'].fmeasure\n",
        "        total_rouge2 += scores['rouge2'].fmeasure\n",
        "        total_rougeL += scores['rougeL'].fmeasure\n",
        "\n",
        "    # Calculate and print average ROUGE scores\n",
        "    avg_rouge1 = total_rouge1 / num_comparisons\n",
        "    avg_rouge2 = total_rouge2 / num_comparisons\n",
        "    avg_rougeL = total_rougeL / num_comparisons\n",
        "\n",
        "    print(\"Overall Average ROUGE Scores:\")\n",
        "    print(f\"Average ROUGE-1: {avg_rouge1:.4f}\")\n",
        "    print(f\"Average ROUGE-2: {avg_rouge2:.4f}\")\n",
        "    print(f\"Average ROUGE-L: {avg_rougeL:.4f}\")\n",
        "\n",
        "# Example usage\n",
        "machine_texts, machine_speakers = read_csv('/content/drive/MyDrive/output.csv')\n",
        "human_texts, human_speakers = read_csv('/content/drive/MyDrive/human_transcription_samplecall1.csv')#change to the compared human_transcription.\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "calculate_rouge(machine_texts, human_texts)\n",
        "\n",
        "# Compare speakers\n",
        "compare_speakers(machine_speakers, human_speakers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRqK7QVIOnd0",
        "outputId": "a209af7e-dc63-4d43-a4ce-7103f5fd545a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison 1:\n",
            "Machine Text:  Thank you for calling Nissan.\n",
            "Human Text:  Thank you for calling Nissan.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 2:\n",
            "Machine Text:  My name is Lauren.\n",
            "Human Text:  My name is Lauren.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 3:\n",
            "Machine Text:  Can I have your name?\n",
            "Human Text:  Can I have your name?\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 4:\n",
            "Machine Text:  My name is John Smith.\n",
            "Human Text:  My name is John Smith.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 5:\n",
            "Machine Text:  Thank you, John.\n",
            "Human Text:  Thank you, John.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 6:\n",
            "Machine Text:  How can I help you?\n",
            "Human Text:  How can I help you?\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 7:\n",
            "Machine Text:  I was just calling about to see how much it would cost to update the map in my car.\n",
            "Human Text:  I was just calling about to see how much it would cost to update the map in my car.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 8:\n",
            "Machine Text:  I'd be happy to help you with that today.\n",
            "Human Text:  I'd be happy to help you with that today.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 9:\n",
            "Machine Text:  Did you receive a mailer from us?\n",
            "Human Text:  Did you receive a mailer from us?\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 10:\n",
            "Machine Text:  I did.\n",
            "Human Text:  I did.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 11:\n",
            "Machine Text:  Do you need the customer number?\n",
            "Human Text:  Do you need the customer number?\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 12:\n",
            "Machine Text:  Yes, please.\n",
            "Human Text:  Yes, please.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 13:\n",
            "Machine Text:  Okay.\n",
            "Human Text:  Okay.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 0.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 14:\n",
            "Machine Text:  It's 1-5-2-4-3.\n",
            "Human Text:  It's 1-5-2-4-3.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 15:\n",
            "Machine Text:  Thank you.\n",
            "Human Text:  Thank you.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 16:\n",
            "Machine Text:  And the year making model of your vehicle?\n",
            "Human Text:  And the year making model of your vehicle?\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 17:\n",
            "Machine Text:  Yeah, I have a 2009 Nissan Altima.\n",
            "Human Text:  Yeah, I have a 2009 Nissan Altima.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 18:\n",
            "Machine Text:  Oh, nice car.\n",
            "Human Text:  Oh, nice car.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 19:\n",
            "Machine Text:  Yeah, thank you.\n",
            "Human Text:  Yeah, thank you.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 20:\n",
            "Machine Text:  We really enjoy it.\n",
            "Human Text:  We really enjoy it.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 21:\n",
            "Machine Text:  Okay, I think I found your profile here.\n",
            "Human Text:  Okay, I think I found your profile here.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 22:\n",
            "Machine Text:  Can I have you verify your address and phone number, please?\n",
            "Human Text:  Can I have you verify your address and phone number, please?\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 23:\n",
            "Machine Text:  Yes, it's 1255 North Research Way.\n",
            "Human Text:  Yes, it's 1255 North Research Way.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 24:\n",
            "Machine Text:  That's an RMUTA 84097.\n",
            "Human Text:  That's an RMUTA 84097.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 25:\n",
            "Machine Text:  And my phone number is 801-431-1000.\n",
            "Human Text:  And my phone number is 801-431-1000.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 26:\n",
            "Machine Text:  Thanks, John.\n",
            "Human Text:  Thanks, John.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 27:\n",
            "Machine Text:  I located your information.\n",
            "Human Text:  I located your information.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 28:\n",
            "Machine Text:  The newest version we have available for your vehicle is version 7.7, which was released in March of 2012.\n",
            "Human Text:  The newest version we have available for your vehicle is version 7.7, which was released in March of 2012.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 29:\n",
            "Machine Text:  The price of the new map is $99 plus shipping and tax.\n",
            "Human Text:  The price of the new map is $99 plus shipping and tax.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 30:\n",
            "Machine Text:  Let me go ahead and set up this order for you.\n",
            "Human Text:  Let me go ahead and set up this order for you.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 31:\n",
            "Machine Text:  Well, can we wait just a second?\n",
            "Human Text:  Well, can we wait just a second?\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 32:\n",
            "Machine Text:  I'm not really sure if I can afford it right now.\n",
            "Human Text:  I'm not really sure if I can afford it right now.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 33:\n",
            "Machine Text:  All right, well, here are a few reasons to consider purchasing today.\n",
            "Human Text:  All right, well, here are a few reasons to consider purchasing today.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 34:\n",
            "Machine Text:  It looks as though you have an updated your vehicle for three years.\n",
            "Human Text:  It looks as though you have an updated your vehicle for three years.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 35:\n",
            "Machine Text:  So that would be the equivalent of getting three years' worth of updates for the price of one.\n",
            "Human Text:  So that would be the equivalent of getting three years' worth of updates for the price of one.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 36:\n",
            "Machine Text:  Okay.\n",
            "Human Text:  Okay.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 0.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 37:\n",
            "Machine Text:  In addition, special offers like the current promotion don't come around too often.\n",
            "Human Text:  In addition, special offers like the current promotion don't come around too often.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 38:\n",
            "Machine Text:  I would definitely recommend taking advantage of the extra $50 off before it expires.\n",
            "Human Text:  I would definitely recommend taking advantage of the extra $50 off before it expires.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 39:\n",
            "Machine Text:  Yeah, that did sound pretty good.\n",
            "Human Text:  Yeah, that did sound pretty good.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 40:\n",
            "Machine Text:  If I set this order up for you now, it'll ship out today and for $50.\n",
            "Human Text:  If I set this order up for you now, it'll ship out today and for $50.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 41:\n",
            "Machine Text:  less.\n",
            "Human Text:  less.\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 0.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 42:\n",
            "Machine Text:  Do you have your credit card handy and I can place this order for you now?\n",
            "Human Text:  Do you have your credit card handy and I can place this order for you now?\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Comparison 43:\n",
            "Machine Text:  Yeah, let's go ahead and use your visa.\n",
            "Human Text:  Yeah, let's go ahead and use the visa.\n",
            "ROUGE-1: 0.8889\n",
            "ROUGE-2: 0.7500\n",
            "ROUGE-L: 0.8889\n",
            "----------------------------------------\n",
            "Comparison 44:\n",
            "Machine Text:  My number is...\n",
            "Human Text:  My number is...\n",
            "ROUGE-1: 1.0000\n",
            "ROUGE-2: 1.0000\n",
            "ROUGE-L: 1.0000\n",
            "----------------------------------------\n",
            "Overall Average ROUGE Scores:\n",
            "Average ROUGE-1: 0.9975\n",
            "Average ROUGE-2: 0.9261\n",
            "Average ROUGE-L: 0.9975\n",
            "Speaker Segmentation Accuracy: 0.9318\n"
          ]
        }
      ]
    }
  ]
}
