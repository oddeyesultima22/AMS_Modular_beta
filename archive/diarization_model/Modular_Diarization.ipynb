{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Modular Code Breakdown**"
      ],
      "metadata": {
        "id": "3XwxxRU1KPEg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "diarization_project/\n",
        "\n",
        "├── main.py\n",
        "\n",
        "├── config.py\n",
        "\n",
        "├── audio_processing/\n",
        "\n",
        "│   ├── __init__.py\n",
        "\n",
        "│   ├── transcription.py\n",
        "\n",
        "│   ├── diarization.py\n",
        "\n",
        "│   ├── utils.py\n",
        "\n",
        "├── evaluation/\n",
        "\n",
        "│   ├── __init__.py\n",
        "\n",
        "│   ├── metrics.py\n",
        "\n",
        "│   ├── clean_text.py\n",
        "\n",
        "├── requirements.txt"
      ],
      "metadata": {
        "id": "Qz_Chha9J_3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "config.py\n",
        "\n",
        "This file contains all configuration variables like the Hugging Face token and model paths."
      ],
      "metadata": {
        "id": "Do4Fy0pAJh0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTH_TOKEN = \"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\"\n",
        "OUTPUT_CSV = \"/content/drive/MyDrive/output.csv\"\n",
        "INPUT_AUDIO = \"/content/drive/MyDrive/Test/3.mp3\"\n"
      ],
      "metadata": {
        "id": "IJtfn6v1IoJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "audio_processing/transcription.py\n",
        "\n",
        "Handles transcription using Whisper."
      ],
      "metadata": {
        "id": "VfAKynkaJjy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "def transcribe_audio(audio_file, model_name=\"tiny.en\"):\n",
        "    model = whisper.load_model(model_name)\n",
        "    asr_result = model.transcribe(audio_file)\n",
        "    return asr_result\n"
      ],
      "metadata": {
        "id": "PclZhWlDI-Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "audio_processing/diarization.py\n",
        "\n",
        "Handles speaker diarization using Pyannote."
      ],
      "metadata": {
        "id": "8_qZVVC_Jnhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyannote.audio import Pipeline\n",
        "\n",
        "def diarize_audio(audio_file, auth_token):\n",
        "    pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\", use_auth_token=auth_token)\n",
        "    diarization_result = pipeline(audio_file)\n",
        "    return diarization_result\n"
      ],
      "metadata": {
        "id": "fEVAIAViJA36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "audio_processing/utils.py\n",
        "\n",
        "Helper functions for processing transcription and diarization results."
      ],
      "metadata": {
        "id": "OqzNimrIJrCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyannote.core import Segment\n",
        "\n",
        "def get_text_with_timestamp(transcribe_res):\n",
        "    return [(Segment(item['start'], item['end']), item['text']) for item in transcribe_res['segments']]\n",
        "\n",
        "def add_speaker_info_to_text(timestamp_texts, diarization_result):\n",
        "    spk_text = []\n",
        "    for seg, text in timestamp_texts:\n",
        "        spk = diarization_result.crop(seg).argmax()\n",
        "        spk_text.append((seg, spk, text))\n",
        "    return spk_text\n",
        "\n",
        "def merge_cache(text_cache):\n",
        "    sentence = ''.join([item[-1] for item in text_cache])\n",
        "    spk = text_cache[0][1]\n",
        "    start = text_cache[0][0].start\n",
        "    end = text_cache[-1][0].end\n",
        "    return Segment(start, end), spk, sentence\n",
        "\n",
        "def merge_sentence(spk_text):\n",
        "    PUNC_SENT_END = ['.', '?', '!']\n",
        "    merged_spk_text, pre_spk, text_cache = [], None, []\n",
        "    for seg, spk, text in spk_text:\n",
        "        if spk != pre_spk and pre_spk is not None and text_cache:\n",
        "            merged_spk_text.append(merge_cache(text_cache))\n",
        "            text_cache = [(seg, spk, text)]\n",
        "        elif text and text[-1] in PUNC_SENT_END:\n",
        "            text_cache.append((seg, spk, text))\n",
        "            merged_spk_text.append(merge_cache(text_cache))\n",
        "            text_cache = []\n",
        "        else:\n",
        "            text_cache.append((seg, spk, text))\n",
        "        pre_spk = spk\n",
        "    if text_cache:\n",
        "        merged_spk_text.append(merge_cache(text_cache))\n",
        "    return merged_spk_text\n"
      ],
      "metadata": {
        "id": "vOJBaH_ZJGBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluation/metrics.py\n",
        "\n",
        "Handles evaluation metrics like WER and ROUGE."
      ],
      "metadata": {
        "id": "sf46yPdoJu31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jiwer import wer\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    return wer(reference, hypothesis)\n",
        "\n",
        "def calculate_rouge(reference, hypothesis):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    return scorer.score(reference, hypothesis)\n"
      ],
      "metadata": {
        "id": "ogElOvcuJPaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluation/clean_text.py\n",
        "\n",
        "Handles text cleaning."
      ],
      "metadata": {
        "id": "8hApZYJ4JzIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def clean_text(text):\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(translator).lower()\n"
      ],
      "metadata": {
        "id": "nEu7FOhDJS6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main.py\n",
        "\n",
        "The entry point of the project."
      ],
      "metadata": {
        "id": "vo5MjMIrJ2dv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from config import AUTH_TOKEN, INPUT_AUDIO, OUTPUT_CSV\n",
        "from audio_processing.transcription import transcribe_audio\n",
        "from audio_processing.diarization import diarize_audio\n",
        "from audio_processing.utils import get_text_with_timestamp, add_speaker_info_to_text, merge_sentence\n",
        "from evaluation.metrics import calculate_wer, calculate_rouge\n",
        "\n",
        "def main():\n",
        "    # Step 1: Transcription\n",
        "    asr_result = transcribe_audio(INPUT_AUDIO)\n",
        "\n",
        "    # Step 2: Diarization\n",
        "    diarization_result = diarize_audio(INPUT_AUDIO, AUTH_TOKEN)\n",
        "\n",
        "    # Step 3: Merge results\n",
        "    timestamp_texts = get_text_with_timestamp(asr_result)\n",
        "    spk_text = add_speaker_info_to_text(timestamp_texts, diarization_result)\n",
        "    merged_text = merge_sentence(spk_text)\n",
        "\n",
        "    # Output results\n",
        "    print(\"Merged Transcription and Diarization:\")\n",
        "    for seg, spk, sent in merged_text:\n",
        "        print(f\"Speaker {spk}: {sent}\")\n",
        "\n",
        "    # Optional: Save to CSV\n",
        "    with open(OUTPUT_CSV, 'w') as f:\n",
        "        for seg, spk, sent in merged_text:\n",
        "            f.write(f\"{seg.start},{seg.end},{spk},{sent}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "MBC74HKsJWG_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}