{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1MWinQgskJ0"
      },
      "source": [
        "# Pyannote-Whisper model for AMS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4OUcUeBk5IR",
        "outputId": "73aad144-85a7-481d-f58d-5697f7df7651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-y9jz24qj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-y9jz24qj\n",
            "  Resolved https://github.com/openai/whisper.git to commit 279133e3107392276dc509148da1f41bfb532c7e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.4.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.5)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2.0.0 (from openai-whisper==20231117)\n",
            "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper==20231117) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2024.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802819 sha256=895f49fb72d3687ca953fd9e51adcb4b364fe1c3323c6e6ad49039fd05afe9e8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-m6wbxmz9/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20231117 tiktoken-0.7.0 triton-3.0.0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.2/807.2 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.2/869.2 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyannote.audio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.19.2\n",
            "Collecting git+https://github.com/thomasmol/faster-whisper.git@master\n",
            "  Cloning https://github.com/thomasmol/faster-whisper.git (to revision master) to /tmp/pip-req-build-_3eu0e5r\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/thomasmol/faster-whisper.git /tmp/pip-req-build-_3eu0e5r\n",
            "  Resolved https://github.com/thomasmol/faster-whisper.git to commit 23ba656e0b7df8c3d892698c7428f9fc84593496\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting av==10.* (from faster-whisper==0.9.0)\n",
            "  Downloading av-10.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting ctranslate2<4,>=3.17 (from faster-whisper==0.9.0)\n",
            "  Downloading ctranslate2-3.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface_hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==0.9.0) (0.24.7)\n",
            "Collecting tokenizers<0.15,>=0.13 (from faster-whisper==0.9.0)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting onnxruntime-gpu<2,>=1.16.0 (from faster-whisper==0.9.0)\n",
            "  Downloading onnxruntime_gpu-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->faster-whisper==0.9.0) (71.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->faster-whisper==0.9.0) (1.26.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->faster-whisper==0.9.0) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper==0.9.0) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper==0.9.0) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper==0.9.0) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper==0.9.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper==0.9.0) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper==0.9.0) (4.12.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu<2,>=1.16.0->faster-whisper==0.9.0) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu<2,>=1.16.0->faster-whisper==0.9.0) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu<2,>=1.16.0->faster-whisper==0.9.0) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu<2,>=1.16.0->faster-whisper==0.9.0) (1.13.2)\n",
            "Collecting huggingface_hub>=0.13 (from faster-whisper==0.9.0)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime-gpu<2,>=1.16.0->faster-whisper==0.9.0) (10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper==0.9.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper==0.9.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper==0.9.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper==0.9.0) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime-gpu<2,>=1.16.0->faster-whisper==0.9.0) (1.3.0)\n",
            "Downloading av-10.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctranslate2-3.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.8/36.8 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime_gpu-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (226.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.2/226.2 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: faster-whisper\n",
            "  Building wheel for faster-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for faster-whisper: filename=faster_whisper-0.9.0-py3-none-any.whl size=1540325 sha256=a69d5565a564da53e6f49c2efaecf270adf2805d3da606177c232e4468caad2a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2f65unvh/wheels/3e/d6/8c/11e7ffa1c3316834cb75324768b127f266742f987652e2089f\n",
            "Successfully built faster-whisper\n",
            "Installing collected packages: av, ctranslate2, onnxruntime-gpu, huggingface_hub, tokenizers, faster-whisper\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.24.7\n",
            "    Uninstalling huggingface-hub-0.24.7:\n",
            "      Successfully uninstalled huggingface-hub-0.24.7\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "accelerate 0.34.2 requires huggingface-hub>=0.21.0, but you have huggingface-hub 0.17.3 which is incompatible.\n",
            "transformers 4.44.2 requires huggingface-hub<1.0,>=0.23.2, but you have huggingface-hub 0.17.3 which is incompatible.\n",
            "transformers 4.44.2 requires tokenizers<0.20,>=0.19, but you have tokenizers 0.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed av-10.0.0 ctranslate2-3.24.0 faster-whisper-0.9.0 huggingface_hub-0.17.3 onnxruntime-gpu-1.19.2 tokenizers-0.14.1\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.17.3)\n",
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.25.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
            "  Using cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n",
            "Downloading huggingface_hub-0.25.0-py3-none-any.whl (436 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "Installing collected packages: huggingface_hub, tokenizers\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.17.3\n",
            "    Uninstalling huggingface-hub-0.17.3:\n",
            "      Successfully uninstalled huggingface-hub-0.17.3\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.14.1\n",
            "    Uninstalling tokenizers-0.14.1:\n",
            "      Successfully uninstalled tokenizers-0.14.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "faster-whisper 0.9.0 requires tokenizers<0.15,>=0.13, but you have tokenizers 0.19.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface_hub-0.25.0 tokenizers-0.19.1\n"
          ]
        }
      ],
      "source": [
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! pip install -q git+https://github.com/pyannote/pyannote-audio\n",
        "! pip install onnxruntime\n",
        "! pip install git+https://github.com/thomasmol/faster-whisper.git@master\n",
        "! pip install -U huggingface_hub transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su-69gDlwnCZ",
        "outputId": "f6da3ebb-4cf2-40bc-981e-17a69cd97f21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnHVVyUbw7TX",
        "outputId": "28e02ce4-56e7-42d3-acba-ef59620761b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Test/3.mp3\n"
          ]
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/Test/3.mp3'# upload the sample to google driver\n",
        "#path = os.getcwd() # to get current path\n",
        "print(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "k7Jfx8OI-jzB"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import whisper\n",
        "from pyannote.audio import Pipeline\n",
        "from pyannote.core import Segment, Annotation, Timeline\n",
        "\n",
        "# Define helper functions\n",
        "def get_text_with_timestamp(transcribe_res):\n",
        "    timestamp_texts = []\n",
        "    for item in transcribe_res['segments']:\n",
        "        start = item['start']\n",
        "        end = item['end']\n",
        "        text = item['text']\n",
        "        timestamp_texts.append((Segment(start, end), text))\n",
        "    return timestamp_texts\n",
        "\n",
        "def add_speaker_info_to_text(timestamp_texts, ann):\n",
        "    spk_text = []\n",
        "    for seg, text in timestamp_texts:\n",
        "        spk = ann.crop(seg).argmax()\n",
        "        spk_text.append((seg, spk, text))\n",
        "    return spk_text\n",
        "\n",
        "def merge_cache(text_cache):\n",
        "    sentence = ''.join([item[-1] for item in text_cache])\n",
        "    spk = text_cache[0][1]\n",
        "    start = text_cache[0][0].start\n",
        "    end = text_cache[-1][0].end\n",
        "    return Segment(start, end), spk, sentence\n",
        "\n",
        "PUNC_SENT_END = ['.', '?', '!']\n",
        "\n",
        "def merge_sentence(spk_text):\n",
        "    merged_spk_text = []\n",
        "    pre_spk = None\n",
        "    text_cache = []\n",
        "    for seg, spk, text in spk_text:\n",
        "        if spk != pre_spk and pre_spk is not None and len(text_cache) > 0:\n",
        "            merged_spk_text.append(merge_cache(text_cache))\n",
        "            text_cache = [(seg, spk, text)]\n",
        "            pre_spk = spk\n",
        "        elif text and len(text) > 0 and text[-1] in PUNC_SENT_END:\n",
        "            text_cache.append((seg, spk, text))\n",
        "            merged_spk_text.append(merge_cache(text_cache))\n",
        "            text_cache = []\n",
        "            pre_spk = spk\n",
        "        else:\n",
        "            text_cache.append((seg, spk, text))\n",
        "            pre_spk = spk\n",
        "    if len(text_cache) > 0:\n",
        "        merged_spk_text.append(merge_cache(text_cache))\n",
        "    return merged_spk_text\n",
        "\n",
        "def diarize_text(transcribe_res, diarization_result):\n",
        "    timestamp_texts = get_text_with_timestamp(transcribe_res)\n",
        "    spk_text = add_speaker_info_to_text(timestamp_texts, diarization_result)\n",
        "    res_processed = merge_sentence(spk_text)\n",
        "    return res_processed\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "from pyannote.audio import Pipeline\n",
        "from pyannote.core import Segment\n",
        "import csv\n",
        "import torch\n",
        "\n",
        "import onnxruntime as ort\n",
        "\n",
        "print(ort.get_device())\n",
        "\n",
        "# Main processing workflow\n",
        "def process_audio(audio_file, auth_token):\n",
        "    # Initialize pipeline and model\n",
        "    print(\"Initializing models...\")\n",
        "    try:\n",
        "        pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\",\n",
        "                                            use_auth_token=auth_token)\n",
        "        model = whisper.load_model(\"tiny.en\")# You can change Whisper model, tiny→medium are english-only, large and large-v2 are Multilingual\n",
        "        pipeline.to(torch.device(\"cuda\"))\n",
        "    except Exception as e:\n",
        "        print(f\"Error during model initialization: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Perform transcription and speaker diarization\n",
        "    print(\"Processing audio for transcription and diarization...\")\n",
        "    try:\n",
        "        asr_result = model.transcribe(audio_file)\n",
        "        diarization_result = pipeline(audio_file)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during processing: {e}\")\n",
        "        return None\n",
        "\n",
        "    #Merge results\n",
        "    print(\"Merging transcription and diarization results...\")\n",
        "    final_result = diarize_text(asr_result, diarization_result)\n",
        "\n",
        "    if not final_result:\n",
        "        print(\"No results obtained after merging.\")\n",
        "    else:\n",
        "        print(\"Processing complete.\")\n",
        "\n",
        "    return final_result\n",
        "\n",
        "# Usage example\n",
        "audio_file = path # Update with your actual sample path\n",
        "auth_token = \"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\"  # Set up your token in Hugging Face\n",
        "output_csv = \"/content/drive/MyDrive/output.csv\"  # Specify the CSV file path\n",
        "\n",
        "# Process the audio and get the results\n",
        "result = process_audio(audio_file, auth_token)\n",
        "\n",
        "# Check if the result is valid before attempting to print and save\n",
        "if result:\n",
        "    print(\"Saving the final result to CSV...\")\n",
        "    try:\n",
        "        with open(output_csv, mode='w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([\"Start Time\", \"End Time\", \"Speaker\", \"Text\"])\n",
        "            for seg, spk, sent in result:\n",
        "                line = f'{seg.start:.2f} {seg.end:.2f} {spk} {sent}'\n",
        "                print(line)\n",
        "                writer.writerow([f'{seg.start:.2f}', f'{seg.end:.2f}', spk, sent])\n",
        "        print(f\"Results successfully saved to {output_csv}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving CSV file: {e}\")\n",
        "else:\n",
        "    print(\"No result to print or save.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC_6uplp1B_h",
        "outputId": "c816a7c3-a856-4538-f817-c24a4295a302"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU\n",
            "Initializing models...\n",
            "Processing audio for transcription and diarization...\n",
            "Merging transcription and diarization results...\n",
            "Processing complete.\n",
            "Saving the final result to CSV...\n",
            "0.00 11.44 SPEAKER_00  Hello, my name is Rajesh and I'm here to help you with all of your issues.\n",
            "11.44 18.72 SPEAKER_00  Hey Rajesh, we've been using your product for a few weeks now and today it crashed and we cannot launch it anymore.\n",
            "18.72 22.12 SPEAKER_00  Okay sir, thank you for letting me know.\n",
            "22.12 24.12 SPEAKER_00  And what am I supposed to do now?\n",
            "24.12 27.80 SPEAKER_00  What is the priority of the issue?\n",
            "27.80 29.24 SPEAKER_00  What do you mean the priority?\n",
            "29.24 31.12 SPEAKER_00  It's urgent.\n",
            "31.12 42.32 SPEAKER_00  Priority from 1 to 10 where one means the severity is very low and I can close the ticket now and 10 means the severity is very high and I cannot close the ticket yet.\n",
            "42.32 44.36 SPEAKER_00  It's 20.\n",
            "44.36 46.08 SPEAKER_00  20 meaning?\n",
            "46.08 49.88 SPEAKER_00  Meaning it's people are dying priority.\n",
            "49.88 53.12 SPEAKER_00  But are they dying instantly or slowly maybe?\n",
            "53.12 54.12 SPEAKER_00  What the?\n",
            "54.12 56.60 SPEAKER_00  Can we finally start talking about my problem?\n",
            "56.68 62.16 SPEAKER_00  Okay sir, does the problem have a strategically impact on the business?\n",
            "62.16 63.16 SPEAKER_00  It does.\n",
            "63.16 64.92 SPEAKER_00  The program doesn't work.\n",
            "64.92 69.96 SPEAKER_00  I'm getting an error object reference not set to an instance of an object.\n",
            "69.96 73.12 SPEAKER_00  Is that something on the screen sir?\n",
            "73.12 74.84 SPEAKER_00  Where else could it be?\n",
            "74.84 75.84 SPEAKER_00  Thank you sir.\n",
            "75.84 78.40 SPEAKER_00  Our department is not responsible for screen issues.\n",
            "78.40 82.68 SPEAKER_00  I will now put you through to another team who will help you on that sir okay?\n",
            "82.68 86.08 SPEAKER_00  It is not a screen issue.\n",
            "86.08 87.88 SPEAKER_00  Thank you for calling our support team.\n",
            "87.88 91.48 SPEAKER_00  I will now archive this case but should you have a- Wait a second.\n",
            "91.48 92.48 SPEAKER_00  What?\n",
            "92.48 94.00 SPEAKER_00  You said you will put me through to someone else.\n",
            "94.00 96.24 SPEAKER_00  Not archive this case.\n",
            "96.24 98.72 SPEAKER_00  Okay sir, I will do this now.\n",
            "98.72 101.68 SPEAKER_00  Hello my name is Pavo.\n",
            "101.68 103.28 SPEAKER_00  What can I do for you?\n",
            "103.28 109.08 SPEAKER_00  Hi I'm getting an error object reference not set to an instance of an object.\n",
            "109.08 110.08 SPEAKER_00  Heh.\n",
            "110.08 113.24 SPEAKER_00  Yes, the wet data is nice.\n",
            "113.24 114.24 SPEAKER_00  Thank you.\n",
            "114.24 119.24 SPEAKER_00  Do you speak English?\n",
            "119.24 121.88 SPEAKER_00  Yes, I speak.\n",
            "121.88 125.48 SPEAKER_00  Okay what is problem?\n",
            "125.48 130.20 SPEAKER_00  Object reference not set to an instance of an object.\n",
            "130.20 134.84 SPEAKER_00  Sorry can you repeat please.\n",
            "134.84 141.00 SPEAKER_00  Is there someone around who actually speaks English and knows the product you sell?\n",
            "141.00 144.80 SPEAKER_00  I am sorry I have some phone issue.\n",
            "144.80 149.44 SPEAKER_00  I will now forward this call to someone who has better phone.\n",
            "149.44 152.84 SPEAKER_00  When you're not, my name is Luigi Benidet.\n",
            "152.84 153.84 SPEAKER_00  Really?\n",
            "153.84 155.48 SPEAKER_00  Really really.\n",
            "155.48 157.56 SPEAKER_00  But people need to call me Roberto.\n",
            "157.56 159.76 SPEAKER_00  Why are you calling me when she has to?\n",
            "159.76 163.72 SPEAKER_00  If it's yes to what did you answer to the phone?\n",
            "163.72 165.68 SPEAKER_00  Mmm.\n",
            "165.68 166.68 SPEAKER_00  Mmm.\n",
            "166.68 167.68 SPEAKER_00  Mmm.\n",
            "167.68 168.68 SPEAKER_00  Mmm.\n",
            "168.68 169.68 SPEAKER_00  Mmm.\n",
            "169.68 171.56 SPEAKER_00  You know you call IPcapp.\n",
            "171.56 176.56 SPEAKER_00  Let me transfer you to someone who has no CSDA.\n",
            "176.56 178.04 SPEAKER_00  Let me be honest with you.\n",
            "178.04 179.36 SPEAKER_00  They will not help you.\n",
            "179.36 181.60 SPEAKER_00  We do not support this software.\n",
            "181.60 186.56 SPEAKER_00  We have plenty of solutions in our portfolio but we do not support this one.\n",
            "186.56 189.52 SPEAKER_00  It is company policy for our department.\n",
            "189.52 197.16 SPEAKER_00  So please put me through to someone who knows the answer and is allowed to give it to me.\n",
            "197.24 199.28 SPEAKER_00  Now you are please wait.\n",
            "199.28 204.52 SPEAKER_00  Never in my life have I heard of such a complex issue.\n",
            "204.52 206.60 SPEAKER_00  But as far as I know.\n",
            "206.60 209.16 SPEAKER_00  Is this a fake British accent?\n",
            "209.16 210.00 SPEAKER_00  Yeah.\n",
            "210.00 211.16 SPEAKER_00  I'm sorry.\n",
            "211.16 214.44 SPEAKER_00  I totally understand your problem and I know how to fix it.\n",
            "214.44 216.80 SPEAKER_00  Finally, so what is the solution?\n",
            "216.80 230.08 SPEAKER_00  Since you've been waiting a long time to get connected with the right person, instead of giving you a link to our knowledge base article, let me put you through to an engineer who will give you step-by-step instructions on the phone and make sure it works on your hands.\n",
            "230.08 231.08 SPEAKER_00  Okay.\n",
            "231.08 232.08 SPEAKER_00  That works.\n",
            "232.08 233.08 None  Hello.\n",
            "233.08 234.08 SPEAKER_00  This is Arajesh.\n",
            "234.08 235.08 SPEAKER_00  Hello sir.\n",
            "235.08 237.08 SPEAKER_00  Are you okay?\n",
            "237.08 240.68 SPEAKER_00  I feel you are in pain sir.\n",
            "240.68 244.16 SPEAKER_00  How big is your pain from 1 to 5 billion?\n",
            "Results successfully saved to /content/drive/MyDrive/output.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model metrics\n",
        "We use WER and Rouge to measure the accuracy ASR, Speaker segmentation accuray to measure diarization."
      ],
      "metadata": {
        "id": "CkvSvt10QEY-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFF7bReSErJP",
        "outputId": "4f6c2965-cc66-4198-aaec-25a30b2a2922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.5)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.9.7)\n"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "! pip install rouge_score\n",
        "! pip install jiwer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSSEaXlGSQ-C",
        "outputId": "75a7db5e-5aae-4f11-84a8-5018d92bea82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER for concatenated transcription: 0.0272\n",
            "ROUGE scores for concatenated transcription:\n",
            "ROUGE-1: 0.9797\n",
            "ROUGE-2: 0.9678\n",
            "ROUGE-L: 0.9797\n",
            "Speaker Segmentation Accuracy: 0.1875 (15/80)\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import string\n",
        "from rouge_score import rouge_scorer\n",
        "from jiwer import wer  # For WER calculation\n",
        "\n",
        "# Function to clean text content by removing punctuation and converting to lowercase. This is to delete the format influence.\n",
        "def clean_text(text):\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(translator).lower()\n",
        "\n",
        "# Function to read a CSV file and return lists of cleaned text and speaker information\n",
        "def read_csv(file_path):\n",
        "    texts = []\n",
        "    speakers = []\n",
        "    with open(file_path, mode='r') as file:\n",
        "        reader = csv.reader(file)\n",
        "        next(reader)  # Skip the header row\n",
        "        for row in reader:\n",
        "            text = clean_text(row[3])  # Clean the speaker's content (text)\n",
        "            speaker = row[2]            # Keep speaker label as is\n",
        "            speakers.append(speaker)   # Append speaker information\n",
        "            texts.append(text)         # Append cleaned text content\n",
        "    return texts, speakers\n",
        "\n",
        "# Function to concatenate all text segments for WER and ROUGE calculation\n",
        "def concatenate_texts(texts):\n",
        "    return ' '.join(texts)\n",
        "\n",
        "# Function to calculate WER for the entire transcription\n",
        "def calculate_wer_concatenated(machine_texts, human_texts):\n",
        "    concatenated_machine = concatenate_texts(machine_texts)\n",
        "    concatenated_human = concatenate_texts(human_texts)\n",
        "\n",
        "    # Calculate WER for the concatenated texts\n",
        "    total_wer = wer(concatenated_human, concatenated_machine)\n",
        "    print(f\"WER for concatenated transcription: {total_wer:.4f}\")\n",
        "    return total_wer\n",
        "\n",
        "# Function to calculate ROUGE scores for the entire transcription\n",
        "def calculate_rouge_concatenated(machine_texts, human_texts):\n",
        "    concatenated_machine = concatenate_texts(machine_texts)\n",
        "    concatenated_human = concatenate_texts(human_texts)\n",
        "\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "    # Calculate ROUGE scores for concatenated texts\n",
        "    scores = scorer.score(concatenated_human, concatenated_machine)\n",
        "\n",
        "    print(\"ROUGE scores for concatenated transcription:\")\n",
        "    print(f\"ROUGE-1: {scores['rouge1'].fmeasure:.4f}\")\n",
        "    print(f\"ROUGE-2: {scores['rouge2'].fmeasure:.4f}\")\n",
        "    print(f\"ROUGE-L: {scores['rougeL'].fmeasure:.4f}\")\n",
        "    return scores\n",
        "\n",
        "# Function to save the concatenated scores to a CSV file\n",
        "def save_concatenated_scores_to_csv(file_path, wer_score, rouge_scores, segmentation_accuracy):\n",
        "    with open(file_path, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['Metric', 'Score'])\n",
        "        writer.writerow(['WER', f\"{wer_score:.4f}\"])\n",
        "        writer.writerow(['ROUGE-1', f\"{rouge_scores['rouge1'].fmeasure:.4f}\"])\n",
        "        writer.writerow(['ROUGE-2', f\"{rouge_scores['rouge2'].fmeasure:.4f}\"])\n",
        "        writer.writerow(['ROUGE-L', f\"{rouge_scores['rougeL'].fmeasure:.4f}\"])\n",
        "        writer.writerow(['Speaker Segmentation Accuracy', f\"{segmentation_accuracy:.4f}\"])\n",
        "\n",
        "# Example usage\n",
        "machine_texts, machine_speakers = read_csv('/content/drive/MyDrive/output.csv') #change to the compared machine_transcription.\n",
        "human_texts, human_speakers = read_csv('/content/drive/MyDrive/3.csv')#change to the compared ground truth.\n",
        "\n",
        "#print(f\"Length of machine_speakers: {len(machine_speakers)}\")  # Print the length of machine_speakers\n",
        "#print(f\"Length of human_speakers: {len(human_speakers)}\")  # Print the length of human_speakers\n",
        "\n",
        "\n",
        "# Calculate WER for concatenated text\n",
        "wer_score = calculate_wer_concatenated(machine_texts, human_texts)\n",
        "\n",
        "# Calculate ROUGE scores for concatenated text\n",
        "rouge_scores = calculate_rouge_concatenated(machine_texts, human_texts)\n",
        "\n",
        "# Compare speaker segmentation\n",
        "segmentation_accuracy = compare_speakers(machine_speakers, human_speakers)\n",
        "\n",
        "# Save concatenated scores to a CSV file\n",
        "save_concatenated_scores_to_csv('/content/drive/MyDrive/concatenated_score_output.csv', wer_score, rouge_scores, segmentation_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optional: Agent Identification\n",
        "We can identify the agent by using fuzzy greeting match. But this is not very accurate and now we do not consider the mutiple persons conversation. This is still an infant model."
      ],
      "metadata": {
        "id": "krAPsMUlaZDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import whisper\n",
        "from pyannote.audio import Pipeline\n",
        "from pyannote.core import Segment, Annotation, Timeline\n",
        "\n",
        "# Define helper functions\n",
        "def get_text_with_timestamp(transcribe_res):\n",
        "    timestamp_texts = []\n",
        "    for item in transcribe_res['segments']:\n",
        "        start = item['start']\n",
        "        end = item['end']\n",
        "        text = item['text']\n",
        "        timestamp_texts.append((Segment(start, end), text))\n",
        "    return timestamp_texts\n",
        "\n",
        "def add_speaker_info_to_text(timestamp_texts, ann):\n",
        "    spk_text = []\n",
        "    for seg, text in timestamp_texts:\n",
        "        spk = ann.crop(seg).argmax()\n",
        "        spk_text.append((seg, spk, text))\n",
        "    return spk_text\n",
        "\n",
        "def merge_cache(text_cache):\n",
        "    sentence = ''.join([item[-1] for item in text_cache])\n",
        "    spk = text_cache[0][1]\n",
        "    start = text_cache[0][0].start\n",
        "    end = text_cache[-1][0].end\n",
        "    return Segment(start, end), spk, sentence\n",
        "\n",
        "PUNC_SENT_END = ['.', '?', '!']\n",
        "\n",
        "def merge_sentence(spk_text):\n",
        "    merged_spk_text = []\n",
        "    pre_spk = None\n",
        "    text_cache = []\n",
        "    for seg, spk, text in spk_text:\n",
        "        if spk != pre_spk and pre_spk is not None and len(text_cache) > 0:\n",
        "            merged_spk_text.append(merge_cache(text_cache))\n",
        "            text_cache = [(seg, spk, text)]\n",
        "            pre_spk = spk\n",
        "        elif text and len(text) > 0 and text[-1] in PUNC_SENT_END:\n",
        "            text_cache.append((seg, spk, text))\n",
        "            merged_spk_text.append(merge_cache(text_cache))\n",
        "            text_cache = []\n",
        "            pre_spk = spk\n",
        "        else:\n",
        "            text_cache.append((seg, spk, text))\n",
        "            pre_spk = spk\n",
        "    if len(text_cache) > 0:\n",
        "        merged_spk_text.append(merge_cache(text_cache))\n",
        "    return merged_spk_text\n",
        "\n",
        "def diarize_text(transcribe_res, diarization_result):\n",
        "    timestamp_texts = get_text_with_timestamp(transcribe_res)\n",
        "    spk_text = add_speaker_info_to_text(timestamp_texts, diarization_result)\n",
        "    res_processed = merge_sentence(spk_text)\n",
        "    return res_processed\n",
        "\n",
        "# Function to identify agent based on specific phrases (with fuzzy matching)\n",
        "def identify_agent(merged_spk_text):\n",
        "    agent_phrases = [\"Thank you for calling\", \"How may I help you\"]# Can expand the fuzzy matching scope\n",
        "    agent_speaker = None\n",
        "\n",
        "    for seg, spk, text in merged_spk_text:\n",
        "        for phrase in agent_phrases:\n",
        "             if phrase.lower() in text.lower():  # Fuzzy matching for the phrase\n",
        "                agent_speaker = spk\n",
        "                break\n",
        "        if agent_speaker:\n",
        "            break\n",
        "\n",
        "    return agent_speaker\n",
        "\n",
        "# If there is no match in agent, we stil leave the label as speaker xx.\n",
        "# Function to map speaker labels\n",
        "def map_speaker_labels(merged_spk_text, agent_speaker=None):\n",
        "    speaker_labels = {}\n",
        "    if agent_speaker is not None:\n",
        "        speaker_labels[agent_speaker] = \"Agent\"\n",
        "        # Assuming binary speakers; adjust if more speakers are possible\n",
        "        other_speakers = set(spk for _, spk, _ in merged_spk_text if spk != agent_speaker)\n",
        "        for spk in other_speakers:\n",
        "            speaker_labels[spk] = \"Customer\"\n",
        "    else:\n",
        "        # Assign generic labels like Speaker 1, Speaker 2, etc.\n",
        "        unique_speakers = sorted(set(spk for _, spk, _ in merged_spk_text))\n",
        "        for idx, spk in enumerate(unique_speakers, start=1):\n",
        "            speaker_labels[spk] = f\"Speaker {idx}\"\n",
        "\n",
        "    # Apply labels to the merged_spk_text\n",
        "    labeled_text = []\n",
        "    for seg, spk, text in merged_spk_text:\n",
        "        label = speaker_labels.get(spk, f\"Speaker {spk}\")\n",
        "        labeled_text.append((seg, label, text))\n",
        "\n",
        "    return labeled_text"
      ],
      "metadata": {
        "id": "bdyPjycEaX6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "from pyannote.audio import Pipeline\n",
        "from pyannote.core import Segment\n",
        "import csv\n",
        "import torch\n",
        "\n",
        "import onnxruntime as ort\n",
        "\n",
        "print(ort.get_device())\n",
        "\n",
        "# Takes 3 minutes to run a audio file\n",
        "# Main processing workflow\n",
        "def process_audio(audio_file, auth_token):\n",
        "    # Initialize pipeline and model\n",
        "    print(\"Initializing models...\")\n",
        "    try:\n",
        "        pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\",\n",
        "                                            use_auth_token=auth_token)\n",
        "        model = whisper.load_model(\"tiny.en\")# change this version\n",
        "        pipeline.to(torch.device(\"cuda\"))\n",
        "        #distil_small_en = hf_hub_download(repo_id=\"distil-whisper/distil-small.en\", filename=\"original-model.bin\")\n",
        "        #model = load_model(distil_small_en)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during model initialization: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Perform transcription and speaker diarization\n",
        "    print(\"Processing audio for transcription and diarization...\")\n",
        "    try:\n",
        "        asr_result = model.transcribe(audio_file)\n",
        "        diarization_result = pipeline(audio_file)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during processing: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Merge results\n",
        "    #print(\"Merging transcription and diarization results...\")\n",
        "    #final_result = diarize_text(asr_result, diarization_result)\n",
        "\n",
        "     # Merge results\n",
        "    print(\"Merging transcription and diarization results...\")\n",
        "    merged_spk_text = diarize_text(asr_result, diarization_result)\n",
        "\n",
        "\n",
        "    # Identify the agent\n",
        "    print(\"Identifying the agent...\")\n",
        "    agent_speaker = identify_agent(merged_spk_text)\n",
        "\n",
        "    # Assume two speaker conversation. Assign speaker roles as \"Agent\" or \"Customer\".\n",
        "    final_result = []\n",
        "    for seg, spk, text in merged_spk_text:\n",
        "        if spk == agent_speaker:\n",
        "            speaker_role = \"Agent\"\n",
        "        else:\n",
        "            speaker_role = \"Customer\"\n",
        "        final_result.append((seg, speaker_role, text))\n",
        "\n",
        "\n",
        "    if not final_result:\n",
        "        print(\"No results obtained after merging.\")\n",
        "    else:\n",
        "        print(\"Processing complete.\")\n",
        "\n",
        "    return final_result\n",
        "\n",
        "# Usage example\n",
        "audio_file = path # Update with your actual file path\n",
        "auth_token = \"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\"  # Set up your token in Hugging Face\n",
        "output_csv = \"/content/drive/MyDrive/output/output.csv\"  # Specify the CSV file path\n",
        "\n",
        "# Process the audio and get the results\n",
        "result = process_audio(audio_file, auth_token)\n",
        "\n",
        "# Check if the result is valid before attempting to print and save\n",
        "if result:\n",
        "    print(\"Saving the final result to CSV...\")\n",
        "    try:\n",
        "        with open(output_csv, mode='w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([\"Start Time\", \"End Time\", \"Speaker\", \"Text\"])\n",
        "            for seg, spk, sent in result:\n",
        "                line = f'{seg.start:.2f} {seg.end:.2f} {spk} {sent}'\n",
        "                print(line)\n",
        "                writer.writerow([f'{seg.start:.2f}', f'{seg.end:.2f}', spk, sent])\n",
        "        print(f\"Results successfully saved to {output_csv}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving CSV file: {e}\")\n",
        "else:\n",
        "    print(\"No result to print or save.\")"
      ],
      "metadata": {
        "id": "Lfy2skatfZBg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}