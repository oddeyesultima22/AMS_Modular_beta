{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CallAI - Diarization Model (Version III)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pg/0pf009313s3_ccymmd8dvzzw0000gn/T/ipykernel_25901/3564158976.py:2: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#For extending the width of the boxes\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library to install: librosa, moviepy, resemblyzer, ffmpeg ( use 'brew install ffmpeg' ), SpeechRecognition, soundfile, SpeechRecognition, sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run code below if you haven't install the library above\n",
    "# !pip install -r lib/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.mixture import *\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "\n",
    "from resemblyzer import preprocess_wav, VoiceEncoder\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), 'lib'))\n",
    "from demo_utils import *\n",
    "\n",
    "os.environ[\"IMAGEIO_FFMPEG_EXE\"] = \"/opt/homebrew/bin/ffmpeg\"  # depends on where you install ffmpeg, run 'which ffmpeg' to check\n",
    "\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "\n",
    "import speech_recognition as sr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/bin/ffmpeg\n"
     ]
    }
   ],
   "source": [
    "!which ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quxch/Documents/DEAKIN/2024T2/SIT764/AMS-Project/diarization_model\n"
     ]
    }
   ],
   "source": [
    "# path = '/Users/quxch/Documents/DEAKIN/2024T2/SIT764/NayyarCode/callai_deployment_edited/callai_deployment'\n",
    "\n",
    "path = os.getcwd() # to get current path\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity 1 - Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quxch/Documents/DEAKIN/2024T2/SIT764/AMS-Project/diarization_model/data/sampleCall1.mp3\n",
      "/Users/quxch/Documents/DEAKIN/2024T2/SIT764/AMS-Project/diarization_model/data/sampleCall1.wav\n"
     ]
    }
   ],
   "source": [
    "audio_file_name = 'sampleCall1'\n",
    "audio_file_path = path + f'/data/{audio_file_name}.mp3'\n",
    "wav_fpath = path +  f'/data/{audio_file_name}.wav'\n",
    "print(audio_file_path)\n",
    "print(wav_fpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting mp3 to wav format \n",
    "# Load the audio as a waveform `wav` and Store the sampling rate as `sampling_rate`\n",
    "wav,sampling_rate = librosa.load(audio_file_path, sr=16000)\n",
    "sf.write(wav_fpath, wav, sampling_rate, 'PCM_16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut some segments from single speakers as reference audio\n",
    "# segments = [[6, 10], [11, 13]]\n",
    "segments = [[0, 7], [8, 19]]  #Can choose at any period in the audio, must match each speaker\n",
    "\n",
    "speaker_names = [\"Agent\", \"Customer\"]\n",
    "speaker_wavs = [wav[int(s[0] * sampling_rate):int(s[1] * sampling_rate)] for s in segments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/resemblyzer/voice_encoder.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(weights_fpath, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n"
     ]
    }
   ],
   "source": [
    "encoder = VoiceEncoder(\"cpu\")\n",
    "# print(\"Running the continuous embedding on cpu, this might take a while...\")\n",
    "_, cont_embeds, wav_splits = encoder.embed_utterance(wav, return_partials=True, rate=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_embeds = [encoder.embed_utterance(speaker_wav) for speaker_wav in speaker_wavs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_dict = {name: cont_embeds @ speaker_embed for name, speaker_embed in \n",
    "                   zip(speaker_names, speaker_embeds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive_diarization(similarity_dict, wav, wav_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "times = [((s.start + s.stop) / 2) / sampling_rate for s in wav_splits]\n",
    "rate = 1 / (times[1] - times[0])\n",
    "crop_range = int(np.round(x_crop * rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [((s.start + s.stop) / 2) / sampling_rate for s in wav_splits]\n",
    "\n",
    "labels = [0 for i in range(0,len(wav_splits))]\n",
    "labels_conf = [0 for i in range(0,len(wav_splits))]\n",
    "\n",
    "for i, time in enumerate(times):\n",
    "    similarities = [s[i] for s in similarity_dict.values()]\n",
    "    best = np.argmax(similarities)\n",
    "    name, similarity = list(similarity_dict.keys())[best], similarities[best]\n",
    "    labels[i] = name\n",
    "    labels_conf[i] = similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelling = []\n",
    "start_time = 0\n",
    "\n",
    "for i, time in enumerate(times):\n",
    "\n",
    "    similarities = [s[i] for s in similarity_dict.values()]\n",
    "    best = np.argmax(similarities)\n",
    "    name, similarity = list(similarity_dict.keys())[best], similarities[best]\n",
    "    \n",
    "    # temp = [name, similarity, start_time, time]\n",
    "    # labelling.append(tuple(temp))\n",
    "    # start_time = time\n",
    "\n",
    "    if i > 0 and labels[i] != labels[i-1]:\n",
    "        temp = [labels[i-1], similarity, start_time, time]\n",
    "        labelling.append(tuple(temp))\n",
    "        start_time = time\n",
    "    if i == len(times) - 1:\n",
    "        temp = [labels[i], similarity, start_time, time]\n",
    "        labelling.append(tuple(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker: Agent (confident)\n",
      "Speaker: Agent (confident)\n",
      "Speaker: Agent (confident)\n",
      "Speaker: Agent (confident)\n",
      "Speaker: Agent (confident)\n",
      "Speaker: Agent (confident)\n",
      "Speaker: Agent (confident)\n",
      "Speaker: Agent (confident)\n",
      "Speaker: Agent (confident)\n",
      "Speaker: Agent (confident)\n",
      "Speaker: Agent (confident)\n",
      "Speaker: Agent (confident)\n",
      "Speaker: Agent (confident)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Unknown/No speaker\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (confident)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (uncertain)\n",
      "Speaker: Customer (uncertain)\n",
      "Unknown/No speaker\n",
      "Speaker: Agent (confident)\n",
      "Speaker: Agent (confident)\n",
      "Speaker: Agent (confident)\n",
      "Speaker: Agent (confident)\n",
      "Speaker: Agent (confident)\n",
      "Speaker: Agent (confident)\n",
      "Speaker: Agent (confident)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(0, len(wav_splits)):\n",
    "    similarities = [s[i] for s in similarity_dict.values()]\n",
    "    best = np.argmax(similarities)\n",
    "    name, similarity = list(similarity_dict.keys())[best], similarities[best]\n",
    "\n",
    "    temp = [i, name, similarity]\n",
    "    # labelling.append(tuple(temp))\n",
    "    if similarity > 0.75:\n",
    "       print(\"Speaker: %s (confident)\" % name)\n",
    "    elif similarity > 0.65:\n",
    "       print(\"Speaker: %s (uncertain)\" % name)\n",
    "    else:\n",
    "       print(\"Unknown/No speaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "7.3\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Segment 0 could not be recognized.\n",
      "1\n",
      "111.5\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n"
     ]
    }
   ],
   "source": [
    "input_video_path = wav_fpath\n",
    "output_tmp_path = path + f'/data/tmp/{audio_file_name}_tmp.wav'\n",
    "\n",
    "output_script = []\n",
    "output_labels = []\n",
    "\n",
    "for i in range(0,len(labelling)):\n",
    "\n",
    "    print(i)\n",
    "    \n",
    "    t1 = labelling[i][2]\n",
    "    t2 = labelling[i][3]\n",
    "    print(t2-t1)\n",
    "\n",
    "    ffmpeg_extract_subclip(input_video_path, t1, t2, targetname=output_tmp_path)\n",
    "    \n",
    "    file_audio = sr.AudioFile(output_tmp_path)\n",
    "\n",
    "    # use the audio file as the audio source                                        \n",
    "    r = sr.Recognizer()\n",
    "    with file_audio as source:\n",
    "        audio_text = r.record(source)\n",
    "\n",
    "    try:\n",
    "        #recognize the speech  using Google\n",
    "        output = r.recognize_google(audio_text, language='en-US', show_all=True)\n",
    "        output_labels.append(labelling[i][0])\n",
    "        output_script.append(output)\n",
    "    except sr.UnknownValueError:\n",
    "        #handle segments that cannot be recognized\n",
    "        print(f\"Segment {i} could not be recognized.\")\n",
    "        output_labels.append(labelling[i][0])\n",
    "        output_script.append(None)\n",
    "    except sr.RequestError as e:\n",
    "        #handle API request errors\n",
    "        print(f\"Could not request results from Google API; {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying results\n",
    "for i in range(len(output_labels)):\n",
    "    if output_script[i] is None or output_script[i] == []:\n",
    "        print('{} - Speaker {} : {}'.format(i, output_labels[i], ''))\n",
    "    else:\n",
    "        print('{} - Speaker {} : {}'.format(i, output_labels[i], output_script[i]['alternative'][0]['transcript']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
