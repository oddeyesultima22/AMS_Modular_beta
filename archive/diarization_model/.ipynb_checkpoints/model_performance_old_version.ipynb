{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from rouge_score import rouge_scorer\n",
    "from func_py import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read a CSV file and return lists of text and speaker information\n",
    "def read_csv(file_path):\n",
    "    texts = []\n",
    "    speakers = []\n",
    "    with open(file_path, mode='r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip the header row\n",
    "        for row in reader:\n",
    "            start_time = float(row[0])  # Convert start time to float\n",
    "            end_time = float(row[1])    # Convert end time to float\n",
    "            speaker = row[2]            # Keep speaker as a string\n",
    "            text = row[3]               # Extract text content\n",
    "            speakers.append(speaker)   # Append speaker information\n",
    "            texts.append(text)         # Append text content\n",
    "    return texts, speakers\n",
    "\n",
    "# Function to compare speaker segmentation between machine-generated and human-transcribed data\n",
    "def compare_speakers(machine_speakers, human_speakers):\n",
    "    if len(machine_speakers) != len(human_speakers):\n",
    "        raise ValueError(\"Length of machine speakers and human speakers lists do not match.\")\n",
    "\n",
    "    correct = 0\n",
    "    total = len(machine_speakers)\n",
    "\n",
    "    for m_spk, h_spk in zip(machine_speakers, human_speakers):\n",
    "        if m_spk == h_spk:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    print(f\"Speaker Segmentation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Function to calculate ROUGE scores and display results\n",
    "def calculate_rouge(machine_texts, human_texts):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "    total_rouge1, total_rouge2, total_rougeL = 0, 0, 0\n",
    "    num_comparisons = min(len(machine_texts), len(human_texts))\n",
    "\n",
    "    for i in range(num_comparisons):\n",
    "        machine_text = machine_texts[i]\n",
    "        human_text = human_texts[i]\n",
    "\n",
    "        # Calculate ROUGE scores for the current segment\n",
    "        scores = scorer.score(human_text, machine_text)\n",
    "\n",
    "        # Print ROUGE scores for the current segment\n",
    "        print(f\"Comparison {i+1}:\")\n",
    "        print(f\"Machine Text: {machine_text}\")\n",
    "        print(f\"Human Text: {human_text}\")\n",
    "        print(f\"ROUGE-1: {scores['rouge1'].fmeasure:.4f}\")\n",
    "        print(f\"ROUGE-2: {scores['rouge2'].fmeasure:.4f}\")\n",
    "        print(f\"ROUGE-L: {scores['rougeL'].fmeasure:.4f}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        # Accumulate ROUGE scores\n",
    "        total_rouge1 += scores['rouge1'].fmeasure\n",
    "        total_rouge2 += scores['rouge2'].fmeasure\n",
    "        total_rougeL += scores['rougeL'].fmeasure\n",
    "\n",
    "    # Calculate and print average ROUGE scores\n",
    "    avg_rouge1 = total_rouge1 / num_comparisons\n",
    "    avg_rouge2 = total_rouge2 / num_comparisons\n",
    "    avg_rougeL = total_rougeL / num_comparisons\n",
    "\n",
    "    print(\"Overall Average ROUGE Scores:\")\n",
    "    print(f\"Average ROUGE-1: {avg_rouge1:.4f}\")\n",
    "    print(f\"Average ROUGE-2: {avg_rouge2:.4f}\")\n",
    "    print(f\"Average ROUGE-L: {avg_rougeL:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# machine_texts, machine_speakers = read_csv('/content/drive/MyDrive/output.csv')\n",
    "# human_texts, human_speakers = read_csv('/content/drive/MyDrive/human_transcription_samplecall1.csv')#change to the compared human_transcription.\n",
    "\n",
    "# # Calculate ROUGE scores\n",
    "# calculate_rouge(machine_texts, human_texts)\n",
    "\n",
    "# # Compare speakers\n",
    "# compare_speakers(machine_speakers, human_speakers)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
