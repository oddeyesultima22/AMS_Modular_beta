{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01fe7f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.2.2\n",
      "TensorFlow version: 2.17.0\n",
      "NumPy version: 1.23.5\n",
      "scikit-learn version: 1.4.2\n",
      "Transformers version: 4.44.1\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries and Their Purposes:\n",
    "# - pandas: Used for data manipulation and analysis, particularly for reading and writing CSV files.\n",
    "# - transformers: Provides the BERT model and tokenizer for sequence classification tasks.\n",
    "# - tensorflow: Used for model training, including defining, compiling, and fitting neural networks.\n",
    "# - numpy: Supports numerical operations, such as manipulating arrays and tensors.\n",
    "# - sklearn: Used for splitting data into training and validation sets.\n",
    "\n",
    "# Import Statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "import sklearn\n",
    "import os\n",
    "import glob\n",
    "import logging\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from transformers import TFBertForSequenceClassification, BertTokenizer\n",
    "\n",
    "\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"scikit-learn version:\", sklearn.__version__)\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "\n",
    "# Suppress TensorFlow warnings for cleaner output\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "# Required pip installs for the project (Uncomment to install)\n",
    "\n",
    "# !pip install pandas==2.2.2\n",
    "# !pip install tensorflow==2.17.0\n",
    "# !pip install numpy==1.23.5\n",
    "# !pip install scikit-learn==1.4.2\n",
    "# !pip install transformers==4.44.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "450e31f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire model and tokenizer loaded successfully.\n",
      "\n",
      "Processing file: data/original\\original1.csv\n",
      "Data loaded successfully from data/original\\original1.csv. Number of rows: 32\n",
      "Tokenization completed successfully.\n",
      "Making predictions on the dataset...\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Predictions saved to data/predicted/original1.csv.\n",
      "\n",
      "Processing file: data/original\\original2.csv\n",
      "Data loaded successfully from data/original\\original2.csv. Number of rows: 34\n",
      "Tokenization completed successfully.\n",
      "Making predictions on the dataset...\n",
      "2/2 [==============================] - 8s 243ms/step\n",
      "Predictions saved to data/predicted/original2.csv.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Data Loading and Initial Predictions\n",
    "\n",
    "# Description:\n",
    "# Prediction phase of your multi-task BERT model. It processes input data \n",
    "# containing interaction texts, performs tokenization, executes predictions \n",
    "# for three key elements—Category, Quality, and Sentiment—and saves the \n",
    "# results to the /data/predicted/ directory. The sentiment score is specifically \n",
    "# constrained between 0.1 and 0.9 to maintain a defined range. \n",
    "\n",
    "# Function to scale sentiment output\n",
    "def scale_sentiment_output(x):\n",
    "    return 0.1 + 0.8 * x\n",
    "\n",
    "# Load the entire fine-tuned model and tokenizer\n",
    "def load_fine_tuned_model():\n",
    "    try:\n",
    "        # Load the entire saved model\n",
    "        model_path = os.path.join('fine_tuned_bert', 'saved_model')\n",
    "        model = tf.keras.models.load_model(\n",
    "            model_path,\n",
    "            custom_objects={\n",
    "                'TFBertModel': TFBertModel,\n",
    "                'scale_sentiment_output': scale_sentiment_output\n",
    "            }\n",
    "        )\n",
    "        tokenizer = BertTokenizer.from_pretrained('fine_tuned_bert')\n",
    "        print(\"Entire model and tokenizer loaded successfully.\")\n",
    "        return model, tokenizer\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model or tokenizer: {e}\")\n",
    "        raise\n",
    "\n",
    "# Load and preprocess the data\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"Data loaded successfully from {file_path}. Number of rows: {data.shape[0]}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "# Tokenize the texts\n",
    "def tokenize_texts(tokenizer, texts, max_length=128):\n",
    "    try:\n",
    "        inputs = tokenizer(\n",
    "            texts.tolist(),\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=\"tf\",\n",
    "            max_length=max_length\n",
    "        )\n",
    "        print(\"Tokenization completed successfully.\")\n",
    "        return inputs\n",
    "    except Exception as e:\n",
    "        print(f\"Error during tokenization: {e}\")\n",
    "        raise\n",
    "\n",
    "# Predict using the loaded model\n",
    "def run_prediction_pipeline(data, output_file, model, tokenizer):\n",
    "    # Tokenize the data\n",
    "    inputs = tokenize_texts(tokenizer, data['Text'])\n",
    "    \n",
    "    # Make predictions on the dataset\n",
    "    print(\"Making predictions on the dataset...\")\n",
    "    predictions = model.predict([inputs['input_ids'], inputs['attention_mask']])\n",
    "    \n",
    "    # Extract predictions\n",
    "    predicted_categories = np.argmax(predictions['category_output'], axis=1)\n",
    "    predicted_qualities = np.argmax(predictions['quality_output'], axis=1)\n",
    "    predicted_sentiments = predictions['sentiment_output'].flatten()\n",
    "    \n",
    "    # Convert predicted integer labels back to their respective categories\n",
    "    inverse_category_mapping = {\n",
    "        0: 'Greetings',\n",
    "        1: 'Problem Investigation',\n",
    "        2: 'Closure',\n",
    "        3: 'Account Verification'\n",
    "    }\n",
    "    inverse_quality_mapping = {0: 'Positive', 1: 'Neutral', 2: 'Negative'}\n",
    "    \n",
    "    # Add prediction columns\n",
    "    data['Predicted Category'] = pd.Series(predicted_categories).map(inverse_category_mapping)\n",
    "    data['Predicted Quality'] = pd.Series(predicted_qualities).map(inverse_quality_mapping)\n",
    "    data['Predicted Sentiment'] = predicted_sentiments.round(2)  # Rounded for readability\n",
    "    \n",
    "    # Save the predictions only\n",
    "    data = data[['Person', 'Text', 'Predicted Category', 'Predicted Quality', 'Predicted Sentiment']]\n",
    "    \n",
    "    # Save the updated DataFrame with the predictions\n",
    "    data.to_csv(output_file, index=False)\n",
    "    print(f\"Predictions saved to {output_file}.\")\n",
    "\n",
    "# Run pipeline for all files in the `/data/original/` folder and save to `/data/predicted/`\n",
    "def run_pipeline():\n",
    "    # Load model and tokenizer once\n",
    "    model, tokenizer = load_fine_tuned_model()\n",
    "    \n",
    "    # Get all CSV files in the '/data/original/' directory\n",
    "    input_folder = 'data/original/'\n",
    "    output_folder = 'data/predicted/'\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Find all CSV files in the input folder\n",
    "    file_paths = glob.glob(os.path.join(input_folder, '*.csv'))\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        print(f\"\\nProcessing file: {file_path}\")\n",
    "        data = load_data(file_path)\n",
    "        output_file = os.path.join(output_folder, os.path.basename(file_path))  # Save with the same name in /predicted/\n",
    "        run_prediction_pipeline(data, output_file, model, tokenizer)\n",
    "\n",
    "# Execute the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cf72474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n",
      "\n",
      "Processing file: data/predicted\\original1.csv\n",
      "Data loaded successfully from data/predicted\\original1.csv. Number of rows: 32\n",
      "Tokenization completed successfully.\n",
      "Making predictions on the dataset...\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Predictions saved to data/metrics/original1.csv.\n",
      "\n",
      "Processing file: data/predicted\\original2.csv\n",
      "Data loaded successfully from data/predicted\\original2.csv. Number of rows: 34\n",
      "Tokenization completed successfully.\n",
      "Making predictions on the dataset...\n",
      "2/2 [==============================] - 6s 197ms/step\n",
      "Predictions saved to data/metrics/original2.csv.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Sub-Metric Predictions\n",
    "\n",
    "# Description:\n",
    "# This cell takes the output from Cell 2, which contains customer \n",
    "# interaction data with predictions for Category, Quality, and Sentiment, \n",
    "# and appends additional predictions for various sub-metrics like \n",
    "# \"Thank Customer\" or \"Ask Permission\" using a pre-trained BERT model. \n",
    "# It processes multiple files from the `/data/predicted/` folder, skips \n",
    "# any already predicted files, and saves the updated data with predictions \n",
    "# into the `/data/metrics/` folder. The structure of the original data is \n",
    "# preserved while adding prediction columns for further analysis.\n",
    "\n",
    "# Load and preprocess the data\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"Data loaded successfully from {file_path}. Number of rows: {data.shape[0]}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data from {file_path}: {e}\")\n",
    "        raise\n",
    "\n",
    "# Tokenize the input text using BERT tokenizer\n",
    "def tokenize_texts(tokenizer, texts, max_length=128):\n",
    "    try:\n",
    "        inputs = tokenizer(\n",
    "            texts.tolist(),\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"tf\"\n",
    "        )\n",
    "        print(\"Tokenization completed successfully.\")\n",
    "        return inputs\n",
    "    except Exception as e:\n",
    "        print(f\"Error during tokenization: {e}\")\n",
    "        raise\n",
    "\n",
    "# Function to load an existing model and tokenizer\n",
    "def load_saved_model_and_tokenizer():\n",
    "    try:\n",
    "        # Attempt to load the Keras model\n",
    "        model = tf.keras.models.load_model(\n",
    "            'sent_ana_model',\n",
    "            custom_objects={'TFBertForSequenceClassification': TFBertForSequenceClassification}\n",
    "        )\n",
    "        tokenizer = BertTokenizer.from_pretrained('sent_ana_model')\n",
    "        print(\"Model and tokenizer loaded successfully.\")\n",
    "        return model, tokenizer\n",
    "    except Exception as e:\n",
    "        print(\"No existing model found. Please ensure the model and tokenizer are available.\")\n",
    "        raise e\n",
    "\n",
    "# Make predictions and append the sub-metrics to the DataFrame\n",
    "def make_predictions(model, tokenizer, data, output_file):\n",
    "    try:\n",
    "        # Tokenize the input text\n",
    "        inputs = tokenize_texts(tokenizer, data['Text'])\n",
    "    \n",
    "        # Make predictions for each sub-metric\n",
    "        print(\"Making predictions on the dataset...\")\n",
    "        predictions = model.predict([inputs['input_ids'], inputs['attention_mask']])\n",
    "    \n",
    "        # Assuming the model has multiple output layers for each sub-metric\n",
    "        # Adjust the number of predictions based on your model's architecture\n",
    "        # Example assumes 10 sub-metrics\n",
    "        sub_metrics = [\n",
    "            'Thank Customer',\n",
    "            'Introduce Self',\n",
    "            'Ask Reason',\n",
    "            'Ask Accurate Details',\n",
    "            'Ask Permission',\n",
    "            'Resolve Issue',\n",
    "            'Offer Assistance',\n",
    "            'Thank Again',\n",
    "            'Farewell'\n",
    "        ]\n",
    "    \n",
    "        # Iterate over each sub-metric and add predictions to the DataFrame\n",
    "        for idx, sub_metric in enumerate(sub_metrics, start=0):\n",
    "            predicted_values = np.argmax(predictions[idx], axis=1)\n",
    "            data[f'Predicted {sub_metric}'] = predicted_values\n",
    "    \n",
    "        # Save the results to a CSV file\n",
    "        data.to_csv(output_file, index=False)\n",
    "        print(f\"Predictions saved to {output_file}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction or saving results: {e}\")\n",
    "        raise\n",
    "\n",
    "# Run the pipeline for multiple files in the predicted folder\n",
    "def run_pipeline():\n",
    "    try:\n",
    "        # Load model and tokenizer once\n",
    "        model, tokenizer = load_saved_model_and_tokenizer()\n",
    "    \n",
    "        # Define input and output directories\n",
    "        input_folder = 'data/predicted/'\n",
    "        output_folder = 'data/metrics/'\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "        # Find all CSV files in the input folder\n",
    "        file_paths = glob.glob(os.path.join(input_folder, '*.csv'))\n",
    "    \n",
    "        for file_path in file_paths:\n",
    "            # Skip files that contain \"predictions\" in their filename\n",
    "            if \"predictions\" in file_path.lower():\n",
    "                print(f\"Skipping file: {file_path}\")\n",
    "                continue\n",
    "    \n",
    "            print(f\"\\nProcessing file: {file_path}\")\n",
    "            data = load_data(file_path)\n",
    "            output_file = os.path.join(output_folder, os.path.basename(file_path))  # Save with the same name in /metrics/\n",
    "            make_predictions(model, tokenizer, data, output_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during pipeline execution: {e}\")\n",
    "        raise\n",
    "\n",
    "# Execute the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb963bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: data/metrics\\original1.csv\n",
      "Processing file: data/metrics\\original2.csv\n",
      "All results saved to data/evaluation/combined_evaluation.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 – Evaluations\n",
    "\n",
    "# Description:\n",
    "    \n",
    "# processes all CSV files in the data/metrics directory to comprehensively \n",
    "# evaluate customer interactions. It calculates key metrics such as category \n",
    "# diversity, average quality using a weighted scoring system, and average \n",
    "# predicted sentiment. Additionally, it assesses specific interaction aspects \n",
    "# through predefined sub-metrics, awarding points based on correct predictions. \n",
    "# After validating and standardizing the data, the aggregated results for each \n",
    "# file are compiled and saved into a single CSV file (combined_evaluation.csv) \n",
    "# in the data/evaluation directory for easy comparison and analysis of overall \n",
    "# performance.    \n",
    "\n",
    "# Function to convert weighted average to a category\n",
    "def convert_to_quality_category(avg_score):\n",
    "    if avg_score >= 0.7:\n",
    "        return 'Positive'\n",
    "    elif 0.4 <= avg_score < 0.7:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Negative'\n",
    "\n",
    "def calculate_scores(file_path):\n",
    "    \n",
    "    # Load the data\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Define sub-metric points based on the rubric\n",
    "    sub_metric_points = {\n",
    "        'Thank Customer': 5,\n",
    "        'Introduce Self': 5,\n",
    "        'Ask Reason': 5,\n",
    "        'Ask Accurate Details': 10,\n",
    "        'Ask Permission': 10,\n",
    "        'Resolve Issue': 50,\n",
    "        'Offer Assistance': 5,\n",
    "        'Thank Again': 5,\n",
    "        'Farewell': 5\n",
    "    }\n",
    "\n",
    "    # Calculate the percentage of predicted categories\n",
    "    total_categories = 4  # Total number of categories: Greetings, Account Verification, Problem Investigation, Closure\n",
    "    unique_categories = data['Predicted Category'].nunique()\n",
    "    category_percent = (unique_categories / total_categories) * 100\n",
    "\n",
    "    # Assign weights to quality labels\n",
    "    quality_weights = {'Positive': 0.8, 'Neutral': 0.5, 'Negative': 0.2}\n",
    "\n",
    "    # Replace predicted quality with their corresponding weights\n",
    "    weighted_quality = data['Predicted Quality'].map(quality_weights)\n",
    "\n",
    "    # Calculate the average of the weighted quality\n",
    "    average_weighted_quality = weighted_quality.mean()\n",
    "\n",
    "    # Convert the weighted average into a category (Positive, Neutral, or Negative)\n",
    "    avg_quality_category = convert_to_quality_category(average_weighted_quality)\n",
    "\n",
    "    # Calculate Average Predicted Sentiment\n",
    "    average_predicted_sentiment = round(data['Predicted Sentiment'].mean(), 2)\n",
    "\n",
    "    # Initialize dictionary to store earned points for each sub-metric\n",
    "    earned_points = {}\n",
    "\n",
    "    # Iterate over each sub-metric to assign points\n",
    "    for sub_metric, points in sub_metric_points.items():\n",
    "        predicted_col = f'Predicted {sub_metric}'\n",
    "        \n",
    "        # Filter rows where the predicted sub-metric is 1\n",
    "        relevant_rows = data[data[predicted_col] == 1]\n",
    "        \n",
    "        # Check if any of these rows have correctly predicted the sub-metric\n",
    "        earned_points[sub_metric] = points if not relevant_rows.empty else 0\n",
    "    \n",
    "    # Calculate Overall Score by summing earned points\n",
    "    overall_score = sum(earned_points.values())\n",
    "    overall_score = round(overall_score, 2)\n",
    "\n",
    "    # Prepare the results dictionary\n",
    "    results = {\n",
    "        'file': os.path.basename(file_path),\n",
    "        'category %': round(category_percent, 2),  # The percentage of unique categories\n",
    "        'avg quality': avg_quality_category,  # This is now the weighted category (Positive/Neutral/Negative)\n",
    "        'average_predicted_sentiment': average_predicted_sentiment\n",
    "    }\n",
    "    \n",
    "    # Add sub-metric points to the results\n",
    "    results.update(earned_points)\n",
    "\n",
    "    # Add Overall Score\n",
    "    results['Overall Score'] = overall_score\n",
    "    \n",
    "    return results\n",
    "\n",
    "def process_multiple_files(input_directory, output_file):\n",
    "    \n",
    "    # Find all CSV files in the input directory\n",
    "    file_paths = glob.glob(os.path.join(input_directory, '*.csv'))\n",
    "    \n",
    "    # Initialize an empty list to store all evaluation results\n",
    "    all_results = []\n",
    "\n",
    "    for file in file_paths:\n",
    "        print(f\"Processing file: {file}\")\n",
    "        # Calculate scores and append the results to the list\n",
    "        all_results.append(calculate_scores(file))\n",
    "    \n",
    "    # Convert the list of results into a DataFrame\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Save the results to the specified output CSV file\n",
    "    results_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"All results saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Directory containing evaluation files\n",
    "    input_dir = 'data/metrics'\n",
    "    \n",
    "    # Path to save combined evaluation results\n",
    "    output_file = 'data/evaluation/combined_evaluation.csv'\n",
    "    \n",
    "    # Process all evaluation files in the directory and save to a single file\n",
    "    process_multiple_files(input_dir, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a2719b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-- BERT/\n",
      "    |-- Model1and2Prediction.ipynb\n",
      "    |-- Model1Training.ipynb\n",
      "    `-- Model2Training.ipynb\n",
      "    |-- .ipynb_checkpoints/\n",
      "        |-- Model1and2Prediction-checkpoint.ipynb\n",
      "        |-- Model1Training-checkpoint.ipynb\n",
      "        `-- Model2Training-checkpoint.ipynb\n",
      "    |-- data/\n",
      "        `-- predictionTemplate.xlsx\n",
      "        |-- evaluation/\n",
      "            |-- combined_evaluation.csv\n",
      "            `-- combined_evaluation2.csv\n",
      "        |-- metrics/\n",
      "            |-- original1.csv\n",
      "            `-- original2.csv\n",
      "            |-- FIX THESE/\n",
      "        |-- original/\n",
      "            |-- original1.csv\n",
      "            `-- original2.csv\n",
      "        |-- predicted/\n",
      "            |-- original1.csv\n",
      "            `-- original2.csv\n",
      "        |-- training/\n",
      "            |-- evaluations/\n",
      "                |-- evaluation.csv\n",
      "                `-- evaluationEvaluator.csv\n",
      "            |-- metricEvaluation/\n",
      "                |-- evaluation_predictions.csv\n",
      "                |-- submetricEvaluation.csv\n",
      "                `-- submetricEvaluation2.csv\n",
      "            |-- metricSolution/\n",
      "                |-- metric1_predictions.csv\n",
      "                |-- metric2_predictions.csv\n",
      "                |-- metric3_predictions.csv\n",
      "                |-- metric4_predictions.csv\n",
      "                |-- metric5_predictions.csv\n",
      "                |-- metric6_predictions.csv\n",
      "                `-- predictions.csv\n",
      "            |-- metricTraining/\n",
      "                |-- metric1.csv\n",
      "                |-- metric2.csv\n",
      "                |-- metric3.csv\n",
      "                |-- metric4.csv\n",
      "                |-- metric5.csv\n",
      "                `-- metric6.csv\n",
      "            |-- predictedSolution/\n",
      "                |-- prediction1Solution.csv\n",
      "                |-- prediction2Solution.csv\n",
      "                |-- prediction3Solution.csv\n",
      "                |-- prediction4Solution.csv\n",
      "                `-- prediction5Solution.csv\n",
      "            |-- predictionSolution/\n",
      "                `-- predictions.csv\n",
      "            |-- predictionTraining/\n",
      "                |-- prediction1.csv\n",
      "                |-- prediction2.csv\n",
      "                |-- prediction3.csv\n",
      "                |-- prediction4.csv\n",
      "                |-- prediction5.csv\n",
      "                `-- prediction6.csv\n",
      "    |-- fine_tuned_bert/\n",
      "        |-- config.json\n",
      "        |-- model.h5\n",
      "        |-- special_tokens_map.json\n",
      "        |-- tf_model.h5\n",
      "        |-- tokenizer_config.json\n",
      "        `-- vocab.txt\n",
      "        |-- saved_model/\n",
      "            |-- fingerprint.pb\n",
      "            |-- keras_metadata.pb\n",
      "            `-- saved_model.pb\n",
      "            |-- assets/\n",
      "            |-- variables/\n",
      "                |-- variables.data-00000-of-00001\n",
      "                `-- variables.index\n",
      "        |-- tf_model/\n",
      "            |-- fingerprint.pb\n",
      "            |-- keras_metadata.pb\n",
      "            `-- saved_model.pb\n",
      "            |-- assets/\n",
      "            |-- variables/\n",
      "                |-- variables.data-00000-of-00001\n",
      "                `-- variables.index\n",
      "    |-- sent_ana_model/\n",
      "        |-- config.json\n",
      "        |-- fingerprint.pb\n",
      "        |-- keras_metadata.pb\n",
      "        |-- saved_model.pb\n",
      "        |-- special_tokens_map.json\n",
      "        |-- tf_model.h5\n",
      "        |-- tokenizer_config.json\n",
      "        `-- vocab.txt\n",
      "        |-- assets/\n",
      "        |-- variables/\n",
      "            |-- variables.data-00000-of-00001\n",
      "            `-- variables.index\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def display_tree(startpath):\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print(f\"{indent}{'|-- '}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for i, f in enumerate(files):\n",
    "            connector = '|-- ' if i != len(files) - 1 else '`-- '\n",
    "            print(f\"{subindent}{connector}{f}\")\n",
    "\n",
    "# Call the function with the current directory or specify your directory\n",
    "current_dir = os.getcwd()\n",
    "display_tree(current_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b0832e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
